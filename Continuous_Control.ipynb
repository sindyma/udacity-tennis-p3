{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import torch\n",
    "import time\n",
    "\n",
    "#for viz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#ddpg agent\n",
    "from ddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose which environment to run\n",
    "env_v = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "if env_v == 1:\n",
    "    env = UnityEnvironment(file_name='Reacher.app')\n",
    "elif env_v == 2:\n",
    "    env = UnityEnvironment(file_name='Reacher20.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(scores):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "solved_actor_name = datetime.now().strftime('%m%d_%H%M%S')+\"_actor.pth\"\n",
    "solved_critic_name = datetime.now().strftime('%m%d_%H%M%S')+\"_critic.pth\"\n",
    "solved_scores = datetime.now().strftime('%m%d_%H%M%S')+\"scores.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(episodes=150, max_t=1000, window=100):\n",
    "    agent = Agent(state_size=state_size, action_size=action_size, random_seed=1)\n",
    "    scores_window = deque(maxlen=window)\n",
    "    scores_all = []\n",
    "    actor_losses = []\n",
    "    critic_losses = []\n",
    "    decay_lr_episodes = 10\n",
    "    for i in range(episodes):\n",
    "        start_time = time.time()\n",
    "        t = 0\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "        agent.reset()\n",
    "        while True and t < max_t: #for each time step\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            scores += env_info.rewards                         # update the score (for each agent)\n",
    "            for state,action,reward,next_state,done in zip(states,actions,rewards,next_states,dones):\n",
    "                agent.step(state,action,reward,next_state,done,t)\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            t += 1 #increment time step\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break\n",
    "        scores_window.append(np.mean(scores))\n",
    "        scores_all.append(np.mean(scores))\n",
    "        #Decay the learning rate every n episodes\n",
    "        if i > 1 and i % decay_lr_episodes == 0:\n",
    "            agent.decay_lr()\n",
    "        torch.save(agent.actor_local.state_dict(), \"_chkpt_actor.pth\")\n",
    "        torch.save(agent.critic_local.state_dict(), \"_chkpt_critic.pth\")\n",
    "        np.savetxt(\"_scores.csv\", scores, delimiter=',')   # solved scores\n",
    "        print('E: {}\\tEpisode mean: {:.2f}\\twindow mean: {:.2f}\\tep max: {:.2f}\\ttime: {:.0f}\\tt:{:.0f}'.format(i+1, np.mean(scores), np.mean(scores_window), np.max(scores), (time.time()-start_time), t))\n",
    "        if np.mean(scores_window) >= 30.0 and i >= 101:\n",
    "            print('\\rSolved! Episode: {}\\twindow mean:{:.2f}'.format(i+1,np.mean(scores_window)))\n",
    "            torch.save(agent.actor_local.state_dict(), solved_actor_name)\n",
    "            torch.save(agent.critic_local.state_dict(), solved_critic_name)\n",
    "            break\n",
    "        if i == 50 and np.mean(scores_window) < 0.5:\n",
    "            print('\\rBelow 0.5 at episode 50, stopping training')\n",
    "            break\n",
    "            \n",
    "    return scores_all, scores_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reacher environment v2 - 20 agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 1\tEpisode mean: 1.12\twindow mean: 1.12\tall mean: 1.12\tep max: 2.02\ttime: 261\tt:1001\n",
      "E: 2\tEpisode mean: 2.05\twindow mean: 1.59\tall mean: 1.59\tep max: 4.41\ttime: 555\tt:1001\n",
      "E: 3\tEpisode mean: 3.68\twindow mean: 2.28\tall mean: 2.28\tep max: 5.43\ttime: 850\tt:1001\n",
      "E: 4\tEpisode mean: 5.24\twindow mean: 3.02\tall mean: 3.02\tep max: 6.79\ttime: 1153\tt:1001\n",
      "E: 5\tEpisode mean: 4.98\twindow mean: 3.42\tall mean: 3.42\tep max: 11.45\ttime: 1455\tt:1001\n",
      "E: 6\tEpisode mean: 5.14\twindow mean: 3.70\tall mean: 3.70\tep max: 8.86\ttime: 2264\tt:1001\n",
      "E: 7\tEpisode mean: 5.29\twindow mean: 3.93\tall mean: 3.93\tep max: 9.09\ttime: 3176\tt:1001\n",
      "E: 8\tEpisode mean: 6.30\twindow mean: 4.23\tall mean: 4.23\tep max: 11.74\ttime: 3490\tt:1001\n",
      "E: 9\tEpisode mean: 7.95\twindow mean: 4.64\tall mean: 4.64\tep max: 11.82\ttime: 3806\tt:1001\n",
      "E: 10\tEpisode mean: 8.76\twindow mean: 5.05\tall mean: 5.05\tep max: 12.79\ttime: 4123\tt:1001\n",
      "E: 11\tEpisode mean: 10.68\twindow mean: 5.56\tall mean: 5.56\tep max: 22.67\ttime: 4846\tt:1001\n",
      "E: 12\tEpisode mean: 10.48\twindow mean: 5.97\tall mean: 5.97\tep max: 15.27\ttime: 5896\tt:1001\n",
      "E: 13\tEpisode mean: 11.76\twindow mean: 6.42\tall mean: 6.42\tep max: 20.04\ttime: 6628\tt:1001\n",
      "E: 14\tEpisode mean: 13.57\twindow mean: 6.93\tall mean: 6.93\tep max: 24.17\ttime: 7422\tt:1001\n",
      "E: 15\tEpisode mean: 13.87\twindow mean: 7.39\tall mean: 7.39\tep max: 19.36\ttime: 8438\tt:1001\n",
      "E: 16\tEpisode mean: 14.05\twindow mean: 7.81\tall mean: 7.81\tep max: 20.30\ttime: 9657\tt:1001\n",
      "E: 17\tEpisode mean: 15.60\twindow mean: 8.27\tall mean: 8.27\tep max: 23.76\ttime: 10787\tt:1001\n",
      "E: 18\tEpisode mean: 16.15\twindow mean: 8.71\tall mean: 8.71\tep max: 25.45\ttime: 11852\tt:1001\n",
      "E: 19\tEpisode mean: 19.13\twindow mean: 9.25\tall mean: 9.25\tep max: 24.18\ttime: 12992\tt:1001\n",
      "E: 20\tEpisode mean: 15.77\twindow mean: 9.58\tall mean: 9.58\tep max: 23.23\ttime: 14201\tt:1001\n",
      "E: 21\tEpisode mean: 19.48\twindow mean: 10.05\tall mean: 10.05\tep max: 22.59\ttime: 15294\tt:1001\n",
      "E: 22\tEpisode mean: 20.62\twindow mean: 10.53\tall mean: 10.53\tep max: 28.50\ttime: 16559\tt:1001\n",
      "E: 23\tEpisode mean: 24.06\twindow mean: 11.12\tall mean: 11.12\tep max: 28.21\ttime: 17855\tt:1001\n",
      "E: 24\tEpisode mean: 25.72\twindow mean: 11.73\tall mean: 11.73\tep max: 32.49\ttime: 19147\tt:1001\n",
      "E: 25\tEpisode mean: 29.11\twindow mean: 12.42\tall mean: 12.42\tep max: 37.75\ttime: 20393\tt:1001\n",
      "E: 26\tEpisode mean: 30.78\twindow mean: 13.13\tall mean: 13.13\tep max: 35.47\ttime: 21682\tt:1001\n",
      "E: 27\tEpisode mean: 31.16\twindow mean: 13.80\tall mean: 13.80\tep max: 37.03\ttime: 22977\tt:1001\n",
      "E: 28\tEpisode mean: 33.58\twindow mean: 14.50\tall mean: 14.50\tep max: 36.65\ttime: 24286\tt:1001\n",
      "E: 29\tEpisode mean: 35.76\twindow mean: 15.24\tall mean: 15.24\tep max: 38.26\ttime: 25560\tt:1001\n",
      "E: 30\tEpisode mean: 34.14\twindow mean: 15.87\tall mean: 15.87\tep max: 37.56\ttime: 26875\tt:1001\n",
      "E: 31\tEpisode mean: 34.75\twindow mean: 16.48\tall mean: 16.48\tep max: 38.94\ttime: 28179\tt:1001\n",
      "E: 32\tEpisode mean: 34.76\twindow mean: 17.05\tall mean: 17.05\tep max: 38.15\ttime: 29473\tt:1001\n",
      "E: 33\tEpisode mean: 34.98\twindow mean: 17.59\tall mean: 17.59\tep max: 37.46\ttime: 30777\tt:1001\n",
      "E: 34\tEpisode mean: 34.97\twindow mean: 18.10\tall mean: 18.10\tep max: 37.55\ttime: 32076\tt:1001\n",
      "E: 35\tEpisode mean: 34.45\twindow mean: 18.57\tall mean: 18.57\tep max: 38.44\ttime: 33374\tt:1001\n",
      "E: 36\tEpisode mean: 34.00\twindow mean: 19.00\tall mean: 19.00\tep max: 37.64\ttime: 34699\tt:1001\n",
      "E: 37\tEpisode mean: 33.87\twindow mean: 19.40\tall mean: 19.40\tep max: 37.38\ttime: 35997\tt:1001\n",
      "E: 38\tEpisode mean: 35.58\twindow mean: 19.83\tall mean: 19.83\tep max: 38.64\ttime: 37337\tt:1001\n",
      "E: 39\tEpisode mean: 36.27\twindow mean: 20.25\tall mean: 20.25\tep max: 38.94\ttime: 38661\tt:1001\n",
      "E: 40\tEpisode mean: 36.05\twindow mean: 20.64\tall mean: 20.64\tep max: 39.30\ttime: 39984\tt:1001\n",
      "E: 41\tEpisode mean: 36.25\twindow mean: 21.02\tall mean: 21.02\tep max: 39.39\ttime: 41335\tt:1001\n",
      "E: 42\tEpisode mean: 36.59\twindow mean: 21.39\tall mean: 21.39\tep max: 39.48\ttime: 42677\tt:1001\n",
      "E: 43\tEpisode mean: 37.70\twindow mean: 21.77\tall mean: 21.77\tep max: 39.49\ttime: 43986\tt:1001\n",
      "E: 44\tEpisode mean: 37.15\twindow mean: 22.12\tall mean: 22.12\tep max: 39.54\ttime: 45333\tt:1001\n",
      "E: 45\tEpisode mean: 36.08\twindow mean: 22.43\tall mean: 22.43\tep max: 38.67\ttime: 46668\tt:1001\n",
      "E: 46\tEpisode mean: 36.67\twindow mean: 22.74\tall mean: 22.74\tep max: 38.91\ttime: 47993\tt:1001\n",
      "E: 47\tEpisode mean: 37.32\twindow mean: 23.05\tall mean: 23.05\tep max: 38.94\ttime: 49341\tt:1001\n",
      "E: 48\tEpisode mean: 37.85\twindow mean: 23.36\tall mean: 23.36\tep max: 39.09\ttime: 53098\tt:1001\n",
      "E: 49\tEpisode mean: 38.75\twindow mean: 23.67\tall mean: 23.67\tep max: 39.39\ttime: 53507\tt:1001\n",
      "E: 50\tEpisode mean: 37.47\twindow mean: 23.95\tall mean: 23.95\tep max: 39.33\ttime: 53912\tt:1001\n",
      "E: 51\tEpisode mean: 37.93\twindow mean: 24.22\tall mean: 24.22\tep max: 39.45\ttime: 54315\tt:1001\n",
      "E: 52\tEpisode mean: 37.04\twindow mean: 24.47\tall mean: 24.47\tep max: 39.50\ttime: 54713\tt:1001\n",
      "E: 53\tEpisode mean: 38.25\twindow mean: 24.73\tall mean: 24.73\tep max: 39.41\ttime: 55111\tt:1001\n",
      "E: 54\tEpisode mean: 38.41\twindow mean: 24.98\tall mean: 24.98\tep max: 39.47\ttime: 55504\tt:1001\n",
      "E: 55\tEpisode mean: 37.52\twindow mean: 25.21\tall mean: 25.21\tep max: 39.56\ttime: 55900\tt:1001\n",
      "E: 56\tEpisode mean: 38.06\twindow mean: 25.44\tall mean: 25.44\tep max: 39.27\ttime: 56305\tt:1001\n",
      "E: 57\tEpisode mean: 37.88\twindow mean: 25.66\tall mean: 25.66\tep max: 39.46\ttime: 56707\tt:1001\n",
      "E: 58\tEpisode mean: 37.07\twindow mean: 25.86\tall mean: 25.86\tep max: 39.39\ttime: 57113\tt:1001\n",
      "E: 59\tEpisode mean: 37.23\twindow mean: 26.05\tall mean: 26.05\tep max: 39.32\ttime: 57515\tt:1001\n",
      "E: 60\tEpisode mean: 37.65\twindow mean: 26.24\tall mean: 26.24\tep max: 39.41\ttime: 57917\tt:1001\n",
      "E: 61\tEpisode mean: 37.96\twindow mean: 26.43\tall mean: 26.43\tep max: 39.60\ttime: 58322\tt:1001\n",
      "E: 62\tEpisode mean: 38.63\twindow mean: 26.63\tall mean: 26.63\tep max: 39.52\ttime: 58724\tt:1001\n",
      "E: 63\tEpisode mean: 36.68\twindow mean: 26.79\tall mean: 26.79\tep max: 39.41\ttime: 59127\tt:1001\n",
      "E: 64\tEpisode mean: 36.58\twindow mean: 26.94\tall mean: 26.94\tep max: 39.44\ttime: 59531\tt:1001\n",
      "E: 65\tEpisode mean: 37.46\twindow mean: 27.11\tall mean: 27.11\tep max: 39.42\ttime: 59937\tt:1001\n",
      "E: 66\tEpisode mean: 35.85\twindow mean: 27.24\tall mean: 27.24\tep max: 38.88\ttime: 60348\tt:1001\n",
      "E: 67\tEpisode mean: 37.80\twindow mean: 27.40\tall mean: 27.40\tep max: 39.39\ttime: 60762\tt:1001\n",
      "E: 68\tEpisode mean: 36.69\twindow mean: 27.53\tall mean: 27.53\tep max: 39.51\ttime: 61174\tt:1001\n",
      "E: 69\tEpisode mean: 36.01\twindow mean: 27.66\tall mean: 27.66\tep max: 39.31\ttime: 61588\tt:1001\n",
      "E: 70\tEpisode mean: 36.05\twindow mean: 27.78\tall mean: 27.78\tep max: 38.91\ttime: 62281\tt:1001\n",
      "E: 71\tEpisode mean: 34.82\twindow mean: 27.87\tall mean: 27.87\tep max: 39.00\ttime: 63610\tt:1001\n",
      "E: 72\tEpisode mean: 35.73\twindow mean: 27.98\tall mean: 27.98\tep max: 39.40\ttime: 64741\tt:1001\n",
      "E: 73\tEpisode mean: 35.97\twindow mean: 28.09\tall mean: 28.09\tep max: 38.81\ttime: 65986\tt:1001\n",
      "E: 74\tEpisode mean: 32.49\twindow mean: 28.15\tall mean: 28.15\tep max: 39.19\ttime: 67358\tt:1001\n",
      "E: 75\tEpisode mean: 35.93\twindow mean: 28.26\tall mean: 28.26\tep max: 38.53\ttime: 68360\tt:1001\n",
      "E: 76\tEpisode mean: 34.62\twindow mean: 28.34\tall mean: 28.34\tep max: 38.98\ttime: 69722\tt:1001\n",
      "E: 77\tEpisode mean: 34.82\twindow mean: 28.42\tall mean: 28.42\tep max: 38.26\ttime: 70346\tt:1001\n",
      "E: 78\tEpisode mean: 34.03\twindow mean: 28.50\tall mean: 28.50\tep max: 38.15\ttime: 70960\tt:1001\n",
      "E: 79\tEpisode mean: 35.80\twindow mean: 28.59\tall mean: 28.59\tep max: 38.51\ttime: 71576\tt:1001\n",
      "E: 80\tEpisode mean: 35.31\twindow mean: 28.67\tall mean: 28.67\tep max: 38.42\ttime: 72456\tt:1001\n",
      "E: 81\tEpisode mean: 35.03\twindow mean: 28.75\tall mean: 28.75\tep max: 38.76\ttime: 73355\tt:1001\n",
      "E: 82\tEpisode mean: 37.43\twindow mean: 28.86\tall mean: 28.86\tep max: 38.86\ttime: 74226\tt:1001\n",
      "E: 83\tEpisode mean: 35.54\twindow mean: 28.94\tall mean: 28.94\tep max: 39.51\ttime: 75112\tt:1001\n",
      "E: 84\tEpisode mean: 36.29\twindow mean: 29.02\tall mean: 29.02\tep max: 39.11\ttime: 75927\tt:1001\n",
      "E: 85\tEpisode mean: 36.59\twindow mean: 29.11\tall mean: 29.11\tep max: 39.36\ttime: 76605\tt:1001\n",
      "E: 86\tEpisode mean: 37.84\twindow mean: 29.22\tall mean: 29.22\tep max: 39.19\ttime: 77456\tt:1001\n",
      "E: 87\tEpisode mean: 35.83\twindow mean: 29.29\tall mean: 29.29\tep max: 38.97\ttime: 78129\tt:1001\n",
      "E: 88\tEpisode mean: 36.17\twindow mean: 29.37\tall mean: 29.37\tep max: 38.47\ttime: 79049\tt:1001\n",
      "E: 89\tEpisode mean: 33.91\twindow mean: 29.42\tall mean: 29.42\tep max: 37.04\ttime: 79613\tt:1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 90\tEpisode mean: 35.21\twindow mean: 29.48\tall mean: 29.48\tep max: 38.75\ttime: 80626\tt:1001\n",
      "E: 91\tEpisode mean: 37.55\twindow mean: 29.57\tall mean: 29.57\tep max: 39.10\ttime: 81347\tt:1001\n",
      "E: 92\tEpisode mean: 37.83\twindow mean: 29.66\tall mean: 29.66\tep max: 39.58\ttime: 82012\tt:1001\n",
      "E: 93\tEpisode mean: 37.62\twindow mean: 29.75\tall mean: 29.75\tep max: 39.50\ttime: 84940\tt:1001\n",
      "E: 94\tEpisode mean: 35.79\twindow mean: 29.81\tall mean: 29.81\tep max: 39.08\ttime: 85374\tt:1001\n",
      "E: 95\tEpisode mean: 36.88\twindow mean: 29.89\tall mean: 29.89\tep max: 39.62\ttime: 85805\tt:1001\n",
      "E: 96\tEpisode mean: 35.26\twindow mean: 29.94\tall mean: 29.94\tep max: 38.78\ttime: 86760\tt:1001\n",
      "E: 97\tEpisode mean: 36.73\twindow mean: 30.01\tall mean: 30.01\tep max: 38.91\ttime: 88012\tt:1001\n",
      "Solved! Episode: 97\twindow mean:30.01\n",
      "E: 98\tEpisode mean: 36.55\twindow mean: 30.08\tall mean: 30.08\tep max: 39.19\ttime: 88677\tt:1001\n",
      "Solved! Episode: 98\twindow mean:30.08\n",
      "E: 99\tEpisode mean: 36.81\twindow mean: 30.15\tall mean: 30.15\tep max: 39.39\ttime: 89108\tt:1001\n",
      "Solved! Episode: 99\twindow mean:30.15\n",
      "E: 100\tEpisode mean: 36.93\twindow mean: 30.22\tall mean: 30.22\tep max: 38.99\ttime: 89541\tt:1001\n",
      "Solved! Episode: 100\twindow mean:30.22\n",
      "E: 101\tEpisode mean: 37.77\twindow mean: 30.58\tall mean: 30.29\tep max: 39.40\ttime: 90603\tt:1001\n",
      "Solved! Episode: 101\twindow mean:30.58\n",
      "E: 102\tEpisode mean: 35.54\twindow mean: 30.92\tall mean: 30.34\tep max: 38.32\ttime: 91824\tt:1001\n",
      "Solved! Episode: 102\twindow mean:30.92\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0701c22f01f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cc90321039e8>\u001b[0m in \u001b[0;36mddpg\u001b[0;34m(episodes, max_t, window)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m                         \u001b[0;31m# update the score (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_states\u001b[0m                               \u001b[0;31m# roll over states to next time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m#increment time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/drlnd/deep-reinforcement-learning/p2_continuous-control/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done, timestep)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Learn at defined interval, if enough samples are available in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mLEARN_EVERY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLEARN_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/drlnd/deep-reinforcement-learning/p2_continuous-control/ddpg_agent.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Experience\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"action\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"next_state\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"done\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/drlnd/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    338\u001b[0m                     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mselected_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores, scores_window = ddpg(episodes=500, max_t=3000, window=100)\n",
    "plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 1\tEpisode mean: 0.75\twindow mean: 0.75\tep max: 1.79\ttime: 209\tt:1001\n",
      "E: 2\tEpisode mean: 1.47\twindow mean: 1.11\tep max: 2.97\ttime: 236\tt:1001\n",
      "E: 3\tEpisode mean: 1.97\twindow mean: 1.39\tep max: 3.21\ttime: 238\tt:1001\n",
      "E: 4\tEpisode mean: 2.45\twindow mean: 1.66\tep max: 4.22\ttime: 240\tt:1001\n",
      "E: 5\tEpisode mean: 2.80\twindow mean: 1.89\tep max: 4.35\ttime: 243\tt:1001\n",
      "E: 6\tEpisode mean: 3.20\twindow mean: 2.11\tep max: 5.34\ttime: 728\tt:1001\n",
      "E: 7\tEpisode mean: 3.65\twindow mean: 2.33\tep max: 5.03\ttime: 1184\tt:1001\n",
      "E: 8\tEpisode mean: 3.11\twindow mean: 2.43\tep max: 4.85\ttime: 764\tt:1001\n",
      "E: 9\tEpisode mean: 3.53\twindow mean: 2.55\tep max: 5.50\ttime: 943\tt:1001\n",
      "E: 10\tEpisode mean: 5.07\twindow mean: 2.80\tep max: 8.45\ttime: 1173\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 11\tEpisode mean: 6.06\twindow mean: 3.10\tep max: 12.04\ttime: 753\tt:1001\n",
      "E: 12\tEpisode mean: 6.99\twindow mean: 3.42\tep max: 10.13\ttime: 205\tt:1001\n",
      "E: 13\tEpisode mean: 7.49\twindow mean: 3.73\tep max: 12.63\ttime: 209\tt:1001\n",
      "E: 14\tEpisode mean: 8.25\twindow mean: 4.06\tep max: 17.44\ttime: 212\tt:1001\n",
      "E: 15\tEpisode mean: 8.25\twindow mean: 4.34\tep max: 12.15\ttime: 214\tt:1001\n",
      "E: 16\tEpisode mean: 9.31\twindow mean: 4.65\tep max: 14.52\ttime: 216\tt:1001\n",
      "E: 17\tEpisode mean: 10.88\twindow mean: 5.01\tep max: 18.56\ttime: 672\tt:1001\n",
      "E: 18\tEpisode mean: 12.36\twindow mean: 5.42\tep max: 17.34\ttime: 1143\tt:1001\n",
      "E: 19\tEpisode mean: 12.87\twindow mean: 5.81\tep max: 16.96\ttime: 1140\tt:1001\n",
      "E: 20\tEpisode mean: 13.55\twindow mean: 6.20\tep max: 18.85\ttime: 1184\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 21\tEpisode mean: 14.53\twindow mean: 6.60\tep max: 21.46\ttime: 1130\tt:1001\n",
      "E: 22\tEpisode mean: 15.79\twindow mean: 7.02\tep max: 20.60\ttime: 1141\tt:1001\n",
      "E: 23\tEpisode mean: 18.34\twindow mean: 7.51\tep max: 24.58\ttime: 1173\tt:1001\n",
      "E: 24\tEpisode mean: 17.61\twindow mean: 7.93\tep max: 24.11\ttime: 1140\tt:1001\n",
      "E: 25\tEpisode mean: 17.62\twindow mean: 8.32\tep max: 24.94\ttime: 1109\tt:1001\n",
      "E: 26\tEpisode mean: 20.45\twindow mean: 8.78\tep max: 25.97\ttime: 1175\tt:1001\n",
      "E: 27\tEpisode mean: 21.86\twindow mean: 9.27\tep max: 29.84\ttime: 1154\tt:1001\n",
      "E: 28\tEpisode mean: 23.28\twindow mean: 9.77\tep max: 28.74\ttime: 1178\tt:1001\n",
      "E: 29\tEpisode mean: 22.61\twindow mean: 10.21\tep max: 29.61\ttime: 1164\tt:1001\n",
      "E: 30\tEpisode mean: 23.88\twindow mean: 10.67\tep max: 35.61\ttime: 1133\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 31\tEpisode mean: 26.11\twindow mean: 11.17\tep max: 35.22\ttime: 1189\tt:1001\n",
      "E: 32\tEpisode mean: 25.50\twindow mean: 11.61\tep max: 34.58\ttime: 1146\tt:1001\n",
      "E: 33\tEpisode mean: 28.50\twindow mean: 12.12\tep max: 33.15\ttime: 1182\tt:1001\n",
      "E: 34\tEpisode mean: 30.45\twindow mean: 12.66\tep max: 37.35\ttime: 1179\tt:1001\n",
      "E: 35\tEpisode mean: 32.44\twindow mean: 13.23\tep max: 38.00\ttime: 1190\tt:1001\n",
      "E: 36\tEpisode mean: 32.59\twindow mean: 13.77\tep max: 36.61\ttime: 1193\tt:1001\n",
      "E: 37\tEpisode mean: 33.93\twindow mean: 14.31\tep max: 37.65\ttime: 1204\tt:1001\n",
      "E: 38\tEpisode mean: 33.42\twindow mean: 14.81\tep max: 36.22\ttime: 1181\tt:1001\n",
      "E: 39\tEpisode mean: 34.11\twindow mean: 15.31\tep max: 39.18\ttime: 1155\tt:1001\n",
      "E: 40\tEpisode mean: 33.67\twindow mean: 15.77\tep max: 37.86\ttime: 1188\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 41\tEpisode mean: 36.41\twindow mean: 16.27\tep max: 38.92\ttime: 1178\tt:1001\n",
      "E: 42\tEpisode mean: 36.37\twindow mean: 16.75\tep max: 39.24\ttime: 1180\tt:1001\n",
      "E: 43\tEpisode mean: 36.11\twindow mean: 17.20\tep max: 39.24\ttime: 1212\tt:1001\n",
      "E: 44\tEpisode mean: 36.99\twindow mean: 17.65\tep max: 39.23\ttime: 1182\tt:1001\n",
      "E: 45\tEpisode mean: 37.59\twindow mean: 18.09\tep max: 39.51\ttime: 1212\tt:1001\n",
      "E: 46\tEpisode mean: 37.76\twindow mean: 18.52\tep max: 39.51\ttime: 1202\tt:1001\n",
      "E: 47\tEpisode mean: 37.94\twindow mean: 18.93\tep max: 39.50\ttime: 1166\tt:1001\n",
      "E: 48\tEpisode mean: 38.65\twindow mean: 19.34\tep max: 39.54\ttime: 1183\tt:1001\n",
      "E: 49\tEpisode mean: 38.82\twindow mean: 19.74\tep max: 39.63\ttime: 1209\tt:1001\n",
      "E: 50\tEpisode mean: 38.59\twindow mean: 20.12\tep max: 39.45\ttime: 1184\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 51\tEpisode mean: 38.33\twindow mean: 20.48\tep max: 39.55\ttime: 464\tt:1001\n",
      "E: 52\tEpisode mean: 38.66\twindow mean: 20.83\tep max: 39.47\ttime: 494\tt:1001\n",
      "E: 53\tEpisode mean: 38.75\twindow mean: 21.16\tep max: 39.55\ttime: 537\tt:1001\n",
      "E: 54\tEpisode mean: 38.31\twindow mean: 21.48\tep max: 39.59\ttime: 664\tt:1001\n",
      "E: 55\tEpisode mean: 38.59\twindow mean: 21.79\tep max: 39.60\ttime: 1008\tt:1001\n",
      "E: 56\tEpisode mean: 38.44\twindow mean: 22.09\tep max: 39.57\ttime: 1222\tt:1001\n",
      "E: 57\tEpisode mean: 38.80\twindow mean: 22.38\tep max: 39.52\ttime: 843\tt:1001\n",
      "E: 58\tEpisode mean: 38.04\twindow mean: 22.65\tep max: 39.50\ttime: 664\tt:1001\n",
      "E: 59\tEpisode mean: 38.98\twindow mean: 22.93\tep max: 39.55\ttime: 683\tt:1001\n",
      "E: 60\tEpisode mean: 38.90\twindow mean: 23.20\tep max: 39.59\ttime: 499\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 61\tEpisode mean: 39.01\twindow mean: 23.46\tep max: 39.56\ttime: 266\tt:1001\n",
      "E: 62\tEpisode mean: 38.44\twindow mean: 23.70\tep max: 39.60\ttime: 262\tt:1001\n",
      "E: 63\tEpisode mean: 38.54\twindow mean: 23.93\tep max: 39.52\ttime: 262\tt:1001\n",
      "E: 64\tEpisode mean: 37.98\twindow mean: 24.15\tep max: 39.59\ttime: 2599\tt:1001\n",
      "E: 65\tEpisode mean: 38.15\twindow mean: 24.37\tep max: 39.62\ttime: 265\tt:1001\n",
      "E: 66\tEpisode mean: 38.44\twindow mean: 24.58\tep max: 39.55\ttime: 323\tt:1001\n",
      "E: 67\tEpisode mean: 38.85\twindow mean: 24.79\tep max: 39.49\ttime: 358\tt:1001\n",
      "E: 68\tEpisode mean: 37.94\twindow mean: 24.99\tep max: 39.51\ttime: 501\tt:1001\n",
      "E: 69\tEpisode mean: 37.58\twindow mean: 25.17\tep max: 39.63\ttime: 646\tt:1001\n",
      "E: 70\tEpisode mean: 37.58\twindow mean: 25.35\tep max: 39.41\ttime: 455\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 71\tEpisode mean: 37.18\twindow mean: 25.51\tep max: 39.31\ttime: 520\tt:1001\n",
      "E: 72\tEpisode mean: 38.15\twindow mean: 25.69\tep max: 39.44\ttime: 536\tt:1001\n",
      "E: 73\tEpisode mean: 37.65\twindow mean: 25.85\tep max: 39.36\ttime: 352\tt:1001\n",
      "E: 74\tEpisode mean: 36.23\twindow mean: 25.99\tep max: 39.49\ttime: 481\tt:1001\n",
      "E: 75\tEpisode mean: 34.98\twindow mean: 26.11\tep max: 38.06\ttime: 643\tt:1001\n",
      "E: 76\tEpisode mean: 35.45\twindow mean: 26.24\tep max: 39.45\ttime: 599\tt:1001\n",
      "E: 77\tEpisode mean: 36.46\twindow mean: 26.37\tep max: 39.54\ttime: 460\tt:1001\n",
      "E: 78\tEpisode mean: 35.94\twindow mean: 26.49\tep max: 39.26\ttime: 956\tt:1001\n",
      "E: 79\tEpisode mean: 37.28\twindow mean: 26.63\tep max: 39.58\ttime: 1177\tt:1001\n",
      "E: 80\tEpisode mean: 37.01\twindow mean: 26.76\tep max: 39.19\ttime: 1137\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 81\tEpisode mean: 35.66\twindow mean: 26.87\tep max: 39.27\ttime: 1149\tt:1001\n",
      "E: 82\tEpisode mean: 35.43\twindow mean: 26.97\tep max: 39.33\ttime: 1150\tt:1001\n",
      "E: 83\tEpisode mean: 35.07\twindow mean: 27.07\tep max: 39.51\ttime: 411\tt:1001\n",
      "E: 84\tEpisode mean: 36.07\twindow mean: 27.18\tep max: 39.42\ttime: 463\tt:1001\n",
      "E: 85\tEpisode mean: 35.29\twindow mean: 27.27\tep max: 39.57\ttime: 701\tt:1001\n",
      "E: 86\tEpisode mean: 35.27\twindow mean: 27.37\tep max: 39.19\ttime: 624\tt:1001\n",
      "E: 87\tEpisode mean: 34.53\twindow mean: 27.45\tep max: 38.44\ttime: 656\tt:1001\n",
      "E: 88\tEpisode mean: 35.93\twindow mean: 27.54\tep max: 39.51\ttime: 625\tt:1001\n",
      "E: 89\tEpisode mean: 33.34\twindow mean: 27.61\tep max: 37.12\ttime: 694\tt:1001\n",
      "E: 90\tEpisode mean: 32.69\twindow mean: 27.67\tep max: 39.37\ttime: 446\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 91\tEpisode mean: 33.41\twindow mean: 27.73\tep max: 37.34\ttime: 773\tt:1001\n",
      "E: 92\tEpisode mean: 34.57\twindow mean: 27.80\tep max: 39.57\ttime: 640\tt:1001\n",
      "E: 93\tEpisode mean: 36.41\twindow mean: 27.90\tep max: 39.50\ttime: 596\tt:1001\n",
      "E: 94\tEpisode mean: 36.57\twindow mean: 27.99\tep max: 39.30\ttime: 589\tt:1001\n",
      "E: 95\tEpisode mean: 37.65\twindow mean: 28.09\tep max: 39.58\ttime: 4066\tt:1001\n",
      "E: 96\tEpisode mean: 37.26\twindow mean: 28.19\tep max: 39.09\ttime: 267\tt:1001\n",
      "E: 97\tEpisode mean: 35.99\twindow mean: 28.27\tep max: 38.01\ttime: 271\tt:1001\n",
      "E: 98\tEpisode mean: 36.86\twindow mean: 28.35\tep max: 39.54\ttime: 270\tt:1001\n",
      "E: 99\tEpisode mean: 36.70\twindow mean: 28.44\tep max: 39.00\ttime: 273\tt:1001\n",
      "E: 100\tEpisode mean: 33.83\twindow mean: 28.49\tep max: 39.09\ttime: 1141\tt:1001\n",
      "New lrs... 0.0009000000000000001 0.0009000000000000001\n",
      "E: 101\tEpisode mean: 36.89\twindow mean: 28.85\tep max: 39.26\ttime: 1216\tt:1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 102\tEpisode mean: 38.34\twindow mean: 29.22\tep max: 39.37\ttime: 1173\tt:1001\n",
      "E: 103\tEpisode mean: 37.37\twindow mean: 29.58\tep max: 39.17\ttime: 1155\tt:1001\n",
      "E: 104\tEpisode mean: 37.50\twindow mean: 29.93\tep max: 39.37\ttime: 1200\tt:1001\n",
      "E: 105\tEpisode mean: 35.05\twindow mean: 30.25\tep max: 37.75\ttime: 788\tt:1001\n",
      "Solved! Episode: 105\twindow mean:30.25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores, scores_window = ddpg(episodes=500, max_t=3000, window=100)\n",
    "np.savetxt(solved_scores, scores, delimiter=',')   # solved scores\n",
    "plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=1)\n",
    "agent.actor_local.load_state_dict(torch.load('0710_200757_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('0710_200757_critic.pth'))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment\n",
    "agent.reset()\n",
    "\n",
    "for t in range(1000):\n",
    "    actions = agent.act(env_info.vector_observations, add_noise=False)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    if np.any(env_info.local_done):\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
